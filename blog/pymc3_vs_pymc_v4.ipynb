{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e991cb4",
   "metadata": {},
   "source": [
    "(v4_announcement)=\n",
    "\n",
    "# PyMC 4.0 Release Announcement\n",
    ":::{post} Apr 4, 2022\n",
    ":tags: release, aesara, jax\n",
    ":category: news\n",
    ":author: Thomas Wiecki\n",
    "\n",
    "We, the PyMC core development team, are incredibly excited to announce the release of a major rewrite of PyMC3 (now called just PyMC): `4.0`. This marks the first major new version in over 10 years. Internally, we have already been using PyMC 4.0 almost exclusively for many months and found it to be very stable and better in every aspect. Every user should upgrade, as there are many exciting new updates that we will talk about in this and upcoming blog posts. \n",
    "\n",
    "## Full API compatibility for model building\n",
    "\n",
    "To get the main question out of the way: Yes, you can just keep your existing PyMC modeling code without having to change anything (in most cases) and get all the improvements for free. The only thing most users will have to change is the import from `import pymc3 as pm` to `import pymc as pm`. For more information, see the [quick migration guide](https://www.pymc-labs.io/blog-posts/the-quickest-migration-guide-ever-from-pymc3-to-pymc-v40/). If you are using more advanced features of PyMC beyond the modeling API, you might have to change some things.\n",
    "\n",
    "## It's now called PyMC instead of PyMC3\n",
    "First, the biggest news: **PyMC3 has been renamed to PyMC. PyMC3 version 3.x will stay under the current name to not break production systems but future versions will use the PyMC name everywhere.** While there were a few reasons for this, the main one is that PyMC3 4.0 looks quite confusing.\n",
    "\n",
    "## What about PyMC4?\n",
    "If you don't know what PyMC4 is, you can just skip this section. In brief, it was an experiment we did using TensorFlow Probability as a backend which we gave up on. The motivation for abandoning this is described in our previous post [\"The Future of PyMC3, or: Theano is Dead, Long Live Theano\"](https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b)\n",
    "\n",
    "In general, you should refer to this new version as \"PyMC 4.0\".\n",
    "\n",
    "## Theano â†’ Aesara\n",
    "\n",
    "Getting to know other tensor libraries like `TensorFlow` and `PyTorch` better made us realize how amazing and unique `Theano` really was. It has a mature and hackable code base and a simple graph representation that allows easy graph manipulations, something that's very useful for probabilistic programming languages. In addition, `TensorFlow` and `PyTorch` focus on a dynamic graph which is useful for some things, but for a probabilistic programming package, a static graph is actually much better, and `Theano` is the only library that provides this.\n",
    "\n",
    "So, we went ahead and forked the `Theano` library and undertook a massive cleaning up of the code-base (this charge was led by [Brandon Willard](https://twitter.com/brandontwillard)), removing swaths of old and obscure code, and restructuring the entire library to be more developer friendly.\n",
    "\n",
    "This rewrite motivated renaming the package to [`Aesara`](https://github.com/aesara-devs/aesara) (Theano's daughter in Greek mythology). Quickly, a new developer team focused around improving `aesara` independent of `PyMC`.\n",
    "\n",
    "One major new feature are support for other computational backends, namely `JAX` and `numba`. The way this works is that `aesara` is best understood as a computational graph library that allows you to build a computational graph out of array-operations (additions, multiplications, dot-products, indexing, for-loops). From this graph representation, we can do various things:\n",
    "* graph optimizations like `log(exp(x)) -> x`\n",
    "* symbolic rewrites like `N(0, 1) + a` -> `N(a, 1)`\n",
    "* compilation of that graph to various computational backends.\n",
    "\n",
    "Previously, `theano` supported Python and C as computational backends. But with `aesara` it is now possible, and in fact quite easy, to add new computational backends. We have currently added a `JAX` backend that comes with GPU support (see [this blog post](https://martiningram.github.io/mcmc-comparison/) for some impressive speed-ups using GPUs for sampling). We're also in the process of adding a `numba` backend.\n",
    "\n",
    "For more information on how `aesara` works, see [this blog post by Ricardo Vieira]().\n",
    "\n",
    "## What's new in PyMC 4.0?\n",
    "\n",
    "Alright, let's get to the good stuff. What makes PyMC 4.0 so awesome?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6961936e",
   "metadata": {},
   "source": [
    "### New JAX backend for faster sampling\n",
    "\n",
    "By far the most exciting new feature are the new computational backends and the associated speed-ups. \n",
    "\n",
    "As mentioned above, `aesara` provides a representation of the model logp graph in form of various `aesara` `Ops` (operators) which represent the computations to be be performed. For example `exp(x + y)` would be an `Add` `Op` with two input arguments `x` and `y`. The result of the `Add` `Op` is then inputted into an `exp` `Op`.\n",
    "\n",
    "This computation graph doesn't say anything about how we actually *execute* this graph, however. Before, we would transpile this graph to C-code which would then get compiled, loaded into Python as a C-extension, and then executed. But now, we can just transpile this graph to `JAX` instead.\n",
    "\n",
    "While this by itself is already pretty exciting, because `JAX` is capable of a whole bunch of low-level optimizations which lead to faster model evaluation, our samplers are still written in Python, so there is still some call-overhead. \n",
    "\n",
    "To get rid of this, we can link the `JAX` graph produced by `aesara` with a sampler also written in `JAX`. That way, the model logp evaluation *and* the sampler are one big JAX graph that gets optimized and executed without any Python call-overhead. We currently support a NUTS implementation provided by [`numpyro`](http://pyro.ai/numpyro/) as well as [`blackjax`](https://github.com/blackjax-devs/blackjax).\n",
    "\n",
    "Early experiments and benchmarks show [impressive speed-ups](https://martiningram.github.io/mcmc-comparison/). Here is a small example of how much faster this is on a fairly small and simple model: the hierarchical linear regression of the famous Radon example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb8b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import arviz as a\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "RANDOM_SEED = 8927\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "np.set_printoptions(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8419bfb",
   "metadata": {},
   "source": [
    "In order to do side-by-side comparisons, I installed both, the old `PyMC3` and `Theano` as well as the new `PyMC 4.0` and `Aesara` into this environment. You will only need the new packages of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1892286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "# PyMC Imports\n",
    "import pymc3 as pm3 # PyMC3 3.11\n",
    "import pymc as pm4 # PyMC 4.0\n",
    "\n",
    "# Aesara and Theano imports\n",
    "import theano.tensor as tt # used by PyMC3 3.11\n",
    "import theano\n",
    "import aesara.tensor as at # used by PyMC 4.0\n",
    "import aesara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a069b",
   "metadata": {},
   "source": [
    "Load in radon dataset and preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56593190",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/twiecki/personal/homepage/WhileMyMCMCGentlySamples/content/radon.csv\")\n",
    "#data = pd.read_csv(pm4.get_data(\"radon.csv\"))\n",
    "county_names = data.county.unique()\n",
    "\n",
    "data[\"log_radon\"] = data[\"log_radon\"].astype(theano.config.floatX)\n",
    "\n",
    "county_idx, counties = pd.factorize(data.county)\n",
    "coords = {\n",
    "    \"county\": counties,\n",
    "    \"obs_id\": np.arange(len(county_idx)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc4fcc3",
   "metadata": {},
   "source": [
    "Next, let's define our model inside of a function. Note that we provide `pm`, our PyMC library, as an argument here. This is a bit unusual but allows us to create this model in `pymc3` or `pymc 4.0`, depending on which module we pass in. Here you can also see that most models that work in `pymc3` also work in `pymc 4.0` without any code change, you only need to change your imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5677df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pm, **kwargs):\n",
    "    with pm.Model(coords=coords) as hierarchical_model:\n",
    "        mu_a = pm.Normal(\"mu_a\", mu=0.0, sigma=10)\n",
    "        sigma_a = pm.HalfNormal(\"sigma_a\", 5.0)\n",
    "        mu_b = pm.Normal(\"mu_b\", mu=0.0, sigma=10)\n",
    "        sigma_b = pm.HalfNormal(\"sigma_b\", 5.0)\n",
    "        a = pm.Normal(\"a\", dims=\"county\") * sigma_a + mu_a\n",
    "        b = pm.Normal(\"b\", dims=\"county\") * sigma_b + mu_b\n",
    "        eps = pm.HalfNormal(\"eps\", 5.0)\n",
    "        radon_est = a[county_idx] + b[county_idx] * data.floor.values\n",
    "        radon_like = pm.Normal(\n",
    "            \"radon_like\", mu=radon_est, sigma=eps, observed=data.log_radon, \n",
    "            dims=\"obs_id\"\n",
    "        )\n",
    "        \n",
    "    return hierarchical_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430fff1c",
   "metadata": {},
   "source": [
    "Create and sample model in `pymc3`, nothing special:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d8528b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [eps, b, a, sigma_b, mu_b, sigma_a, mu_a]\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:04<00:00 Sampling 4 chains, 145 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 12 seconds.\n",
      "There were 90 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7165232860911727, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 49 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7212171537898012, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 6 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 s, sys: 423 ms, total: 3.32 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_pymc3 = build_model(pm3)\n",
    "with model_pymc3:\n",
    "    idata_pymc3 = pm3.sample(return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26c73f",
   "metadata": {},
   "source": [
    "Create and sample model in `pymc` 4.0, also nothing special (but note that `pm.sample()` now returns and `InferenceData` object by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aad554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [mu_a, sigma_a, mu_b, sigma_b, a, b, eps]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:05<00:00 Sampling 4 chains, 24 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 12 seconds.\n",
      "There were 6 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 18 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 356 ms, total: 4.65 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_pymc4 = build_model(pm4)\n",
    "with model_pymc4:\n",
    "    idata_pymc4 = pm4.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d0dcc",
   "metadata": {},
   "source": [
    "Now, lets use a JAX sampler instead. Here we use the one provided by `numpyro`. These samplers live in a different submodule `sampling_jax` but the plan is to integrate them into `pymc.sample(backend=\"JAX\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9cab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n",
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/aesara/link/jax/dispatch.py:87: UserWarning: JAX omnistaging couldn't be disabled: Disabling of omnistaging is no longer supported in JAX version 0.2.12 and higher: see https://github.com/google/jax/blob/main/design_notes/omnistaging.md.\n",
      "  warnings.warn(f\"JAX omnistaging couldn't be disabled: {e}\")\n",
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/pymc/sampling_jax.py:36: UserWarning: This module is experimental.\n",
      "  warnings.warn(\"This module is experimental.\")\n"
     ]
    }
   ],
   "source": [
    "import pymc.sampling_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901becb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling...\n",
      "Compilation time =  0:00:00.751909\n",
      "Sampling...\n",
      "Sampling time =  0:00:04.354319\n",
      "Transforming variables...\n",
      "Transformation time =  0:00:00.026623\n",
      "CPU times: user 7.24 s, sys: 78.9 ms, total: 7.32 s\n",
      "Wall time: 5.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with model_pymc4:\n",
    "    idata = pm4.sampling_jax.sample_numpyro_nuts(progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a40ed445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling...\n",
      "Compilation time =  0:00:00.677075\n",
      "Sampling...\n",
      "Sampling time =  0:00:06.728095\n",
      "Transforming variables...\n",
      "Transformation time =  0:00:00.855364\n",
      "CPU times: user 10.3 s, sys: 75.3 ms, total: 10.4 s\n",
      "Wall time: 8.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with model_pymc4:\n",
    "    idata = pm4.sampling_jax.sample_blackjax_nuts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daba83c",
   "metadata": {},
   "source": [
    "That's a speed-up of 3x -- for a single-line code change! And this is just running things on the CPU, we can just as easily run this on the GPU where we saw even more impressive speed-ups (especially as we scale the data).\n",
    "\n",
    "Again, for a more proper benchmark that also compares this to Stan, see [this blog post](https://martiningram.github.io/mcmc-comparison/).\n",
    "\n",
    "#### The Future: Samplers written in `aesara`\n",
    "\n",
    "While this current approach is already quite exciting, we can take this one step further. The setup we showed above takes the model logp graph (represented in `aesara`) and compiles it to `JAX`. The resulting `JAX` function we can then call from a sampler written in directly in `JAX` (i.e. `numpyro` or `blackjax`).\n",
    "\n",
    "While lightning fast, this is suboptimal for two reasons:\n",
    "1. For new backends, like `numba`, we would need to rewrite the sampler also in `numba`.\n",
    "2. While we get low-level optimizations from `JAX` on the logp+sampler JAX-graph, we do not get any high-level optimizations, which is what `aesara` is great at, because `aesara` does not see the sampler.\n",
    "\n",
    "With [`aehmc`](https://www.github.com/aesara-devs/aehmc) and [`aemcmc`](https://www.github.com/aesara-devs/aemcmc) the `aesara` devs are developing a library of samplers *written in `aesara`*. That way, our model logp, consisting out of `aesara` `Ops` can then be combined with the sampler logic, now also consisting out of `aesara` `Ops`, and form one big `aesara` graph.\n",
    "\n",
    "On that big graph containing model *and* sampler, `aesara` can the do high-level optimizations to get a more efficient graph representation. In a next step it can then compile it to whatever backend we want: `JAX`, `numba`, `C`, or whatever other backend we add in the future.\n",
    "\n",
    "If you think this is interesting, definitely check out these packages and consider contributing, this is where the next round of innovation will come from!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81f0cd",
   "metadata": {},
   "source": [
    "## Better integration into `aesara`\n",
    "\n",
    "The next feature we are excited about is a better integration of `PyMC` into `aesara`.\n",
    "\n",
    "In `PyMC3 3.x`, the random variables (RVs) created by e.g. calling `x = pm.Normal('x')` were not truly `theano` `Ops` so they did not integrate as nicely with the rest of `theano`. This created a lot of issues, limitations, and complexities in the library.\n",
    "\n",
    "`Aesara` now provides a proper `RandomVariable` Op which perfectly integrates with the rest of the other `Ops`. \n",
    "\n",
    "This is a major change in `4.0` and lead to huge swaths of brittle code in PyMC3 get removed or greatly simplified. In many ways, this change is much more exciting than the different computational backends, but the effects are not quite as visible to the user.\n",
    "\n",
    "There are a few cases, however, where you can see the benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2b973",
   "metadata": {},
   "source": [
    "### Faster posterior predictive sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be9adfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4000/4000 01:33<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 3.6 s, total: 1min 33s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with model_pymc3:\n",
    "    pm3.sample_posterior_predictive(idata_pymc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ef50e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4000/4000 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 s, sys: 12.7 ms, total: 3.93 s\n",
      "Wall time: 3.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with model_pymc4:\n",
    "    pm4.sample_posterior_predictive(idata_pymc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15599440",
   "metadata": {},
   "source": [
    "On this model, we get a speed-up of 22x!\n",
    "\n",
    "The reason for this is that predictive sampling is now happening as part of the `aesara` graph. Before, we were walking through the random variables in Python which was not only slow, but also very error-prone, so a lot of dev time was spent fixing bugs and rewriting this complicated piece of code. In `PyMC` 4.0, all that complexity is gone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ea093",
   "metadata": {},
   "source": [
    "## Work with RVs just like with Tensors\n",
    "\n",
    "In PyMC3, RVs as returned by e.g. `pm.Normal(\"x\")` behaved somewhat like a Tensor variable, but not *quite*. In PyMC 4.0, RVs are first-class Tensor variables that can be operated on much more freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c21f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm3.Model():\n",
    "    x3 = pm3.Normal(\"x\")\n",
    "    \n",
    "with pm4.Model():\n",
    "    x4 = pm4.Normal(\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96bf2513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pymc3.model.FreeRV"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4974298a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aesara.tensor.var.TensorVariable"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db22a81f",
   "metadata": {},
   "source": [
    "Through the power of [`aeppl`](https://github.com/aesara-devs/aeppl) (a new low-level library that provides core building blocks for probabilistic programming languages on top of `aesara`), PyMC 4.0 allows you to do even more operations directly on the RV.\n",
    "\n",
    "For example, we can just call `aesara.tensor.clip()` on a RV to truncate certain parameter ranges. Separately, calling `.eval()` on a RV samples a random draw from the RV, this is also new in PyMC 4.0 and makes things more consistent and allows easy interactions with RVs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78504a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.clip(x4, 0, np.inf).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eea963c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trunc_norm = [at.clip(x4, 0, np.inf).eval() for _ in range(1000)]\n",
    "sns.histplot(np.asarray(trunc_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b741ff",
   "metadata": {},
   "source": [
    "As you can see, negative values are clipped to be 0. And you can use this, just like any other transform, directly in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba592c9",
   "metadata": {},
   "source": [
    "But there are other things you can do as well, like `stack()` RVs, and then index into them with a binary RV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a42b3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled value = -0.42\n",
      "Sampled value = 0.80\n",
      "Sampled value = -0.66\n",
      "Sampled value = 0.01\n",
      "Sampled value = 0.42\n"
     ]
    }
   ],
   "source": [
    "with pm4.Model():\n",
    "    x = pm4.Uniform(\"x\", lower=-1, upper=0) # only negtive\n",
    "    y = pm4.Uniform(\"y\", lower=0, upper=1) # only positive\n",
    "    xy = at.stack([x, y]) # combined\n",
    "    index = pm4.Bernoulli(\"index\", p=0.5) # index 0 or 1\n",
    "    \n",
    "    indexed_RV = xy[index] # binary index into stacked variable\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"Sampled value = {:.2f}\".format(indexed_RV.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b12cb2",
   "metadata": {},
   "source": [
    "As you can see, depending on whether `index` is `0` or `1` we either sample from the negative or positive uniform. This also supports fancy indexing, so you can manually create complicated mixture distribution using a `Categorical` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77432dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled value = [ 0.68 -0.52 -0.52]\n",
      "Sampled value = [0.04 0.04 0.04]\n",
      "Sampled value = [-0.59 -0.59  0.26]\n",
      "Sampled value = [ 0.24  0.24 -0.56]\n",
      "Sampled value = [ 0.59 -0.41 -0.41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/pymc/distributions/discrete.py:1281: UserWarning: `p` parameters sum to [0.6], instead of 1.0. They will be automatically rescaled. You can rescale them directly to get rid of this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with pm4.Model():\n",
    "    x = pm4.Uniform(\"x\", lower=-1, upper=0)\n",
    "    y = pm4.Uniform(\"y\", lower=0, upper=1)\n",
    "    z = pm4.Uniform(\"z\", lower=1, upper=2)\n",
    "    xyz = at.stack([x, y, z])\n",
    "    index = pm4.Categorical(\"index\", [.3, .3], shape=3)\n",
    "    \n",
    "    index_RV = xyz[index]\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"Sampled value = {}\".format(index_RV.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a426b",
   "metadata": {},
   "source": [
    "## Better (and Dynamic) Shape Support\n",
    "\n",
    "Another big improvement in `PyMC` 4.0 is in how shapes are handled internally. Before, there was also a bunch of complicated and brittle Python code to handle shapes. Internally, we had a joke where we counted how many days had passed until we had discovered a new shape bug. But no more! Now, all shape handling is completely offloaded to `aesara` which handles this properly. As a sid-effect, this better shape support also allows dynamic RV shapes, where the shape depends on another RV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0daf28f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of z = []\n",
      "Value of z = [0.14]\n",
      "Value of z = [ 1.02  0.39 -0.77 -0.6 ]\n",
      "Value of z = [1.05]\n",
      "Value of z = [ 1.2   1.25 -1.8   0.91  0.12 -0.28]\n"
     ]
    }
   ],
   "source": [
    "with pm4.Model() as m:\n",
    "    x = pm4.Poisson('x', 2)\n",
    "    z = pm4.Normal('z', shape=x)\n",
    "    \n",
    "for _ in range(5):\n",
    "    print(\"Value of z = {}\".format(z.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1cec0b",
   "metadata": {},
   "source": [
    "As you can see, the shape of `z` changes with each draw according to the integer sampled by `x`.\n",
    "\n",
    "Note, however, that this does not yet work for posterior inference (i.e. sampling). The reason is that the trace backend (`arviz.InferenceData`) as well as samplers in this case also must support changing dimensionality (like reversible-jump MCMC). There are plans to add this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80cb4cf",
   "metadata": {},
   "source": [
    "## Better NUTS initialization\n",
    "\n",
    "We have also fixed an issue with the default NUTS warm-up which sometimes lead to the sampler getting stuck for a while. While fixing this issue, [Adrian Seyboldt](https://twitter.com/aseyboldt) also came up with a new initialization method that uses the gradients to estimate a better mass-matrix. You can use this (still experimental) feature by calling `pm.sample(init=\"jitter+adapt_diag_grad\")`.\n",
    "\n",
    "Let's try this on the hierarchical regression model from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7c53fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "INFO:pymc:Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "INFO:pymc:Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "INFO:pymc:Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [mu_a, sigma_a, mu_b, sigma_b, a, b, eps]\n",
      "INFO:pymc:NUTS: [mu_a, sigma_a, mu_b, sigma_b, a, b, eps]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/twiecki/miniforge3/envs/pymc4b5/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 11 seconds.\n",
      "INFO:pymc:Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 11 seconds.\n"
     ]
    }
   ],
   "source": [
    "with model_pymc4:\n",
    "    idata_pymc4_grad = pm4.sample(init=\"jitter+adapt_diag_grad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789798d",
   "metadata": {},
   "source": [
    "The first thing to observe as that we did not get any divergences this time. Comparing the effective sample size of the default and grad-based initialization, we can also see that it leads to much better sampling for certain parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f65f04c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEGCAYAAABcolNbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgb0lEQVR4nO3de5wV9X3/8dfbBbmDysUKWpckxoiwrrioCWpQCd5pjBisUjGJJWjUigFjY23X+miKSmobE/FCDaSiJpGgov4S81Csl6ByWxfQqlHXiKSgxFAgQFA+vz9mdjkse4Uze5bD+/l4nMeZM2fmO9/5ntnz3rmc7ygiMDMzy8o+ha6AmZkVNweNmZllykFjZmaZctCYmVmmHDRmZpapDoWuQNb69OkTpaWlha6GmdkeZfHixR9GRN98lFX0QVNaWsqiRYsKXQ0zsz2KpHfzVZYPnZmZWaYcNGZmlikHjZmZZcpBY2ZmmXLQmJlZphw0ZmaWKQeNmZllykFjZmaZctCYmVmmir5nAFYthcpeha6FmVnbqlxX6BrU8R6NmZllykFjZmaZctCYmVmmHDRmZpYpB42ZmWXKQWNmZply0JiZWaYcNGZmlikHjZmZZapdBI2kcZJellQl6S5JJZI2SPq+pCWSnpLUN532KkmvSqqW9GCh625mZk0reBc0ko4AxgLDI2KrpDuAi4BuwJKI+LakfwT+CbgCuA4YGBFbJO3XSJkTgAkAJT37Urr5x22wJmaWLzVTzyp0FSyP2sMezanAMcBCSVXp608B24CfptPcB5yQDlcDsyWNAz5uqMCIuDsiKiKioqSr+zkzMyuk9hA0AmZFRHn6ODwiKhuYLtLns4AfkYTTYkkF3yszM7PGtYegeQoYI6kfgKQDJB1KUrcx6TQXAs9L2gc4JCLmA9cC+wHd277KZmbWUgXfG4iIVyX9A/BkGiRbgW8BG4EjJS0G1pGcxykB7pPUi2RP6LaI+GNham5mZi1R8KABiIifsv18DACSiIgbgBvqTX4CZma2x2gPh87MzKyItdugiQifezEzKwLtNmjMzKw4OGjMzCxTDhozM8tUu7jqLEtDBvRikbuzMDMrGO/RmJlZphw0ZmaWKQeNmZllykFjZmaZctCYmVmmHDRmZpYpB42ZmWXKQWNmZply0JiZWaYcNGZmlikHjZmZZcpBY2ZmmXLQmJlZphw0ZmaWKQeNmZllykFjZmaZctCYmVmmHDRmZpYpB42ZmWXKQWNmZply0JiZWaY6FLoCmVu1FCp7FboW7U/lukLXwMz2Et6jMTOzTDlozMwsUw4aMzPLlIPGzMwy5aAxM7NMOWjMzCxTDhozM8vULgWNpBmSBuW7Mi1Ybo2kPm29XDMz23W79IPNiLg03xUxM7Pi1OwejaRukh6X9Iqk5ZLGSnpGUkX6/jckvZGOu0fSD9PxMyVNlzRf0tuSvijpXkmvSZqZU/50SYskrZB0YwvqPEXSy+njM7u64mZm1jZaskdzOrAqIs4CkNQLuCwd7g/cAAwF1gNPA6/kzLs/cAowGpgHDAcuBRZKKo+IKuD6iPiDpBLgKUllEVHdRH3+LyKOlXQx8O/A2fUnkDQBmABQ0rMvpZt/3ILV3Mtc9/gOL2umnlWgiphZsWvJOZplwEhJN0s6MSJyO8k6FvjviPhDRGwFfl5v3nkREWkZqyNiWURsA1YApek0X5W0BFgKHAk0d+7ngZznzzc0QUTcHREVEVFR0tX9nJmZFVKzezQR8YakY4AzgX+V9GTO22pm9i3p87ac4drXHSQNBCYDwyLio/SQWufmqtTIsJmZtUMtOUfTH/hTRNwHTCM5TFbrZeCLkvaX1AE4r5XL7wlsBNZJOhA4owXzjM15XtDK5ZmZWRtryTmaIcCtkrYBW0nOz0wDiIj3JX0PeAlYBbwKtLj/+Yh4RdJSkkNpbwMvtGC2TpJeIgnJv27psszMrDCUnELZjQKk7hGxId2jmQvcGxFz81K7POh00GFx0Ph/L3Q12j1fDGBmuSQtjoiKfJSVj54BKiVVAcuBd4CH81CmmZkVid2+w2ZETM5HRXJJmgsMrDf6OxHxq3wvy8zMstUub+UcEecWug5mZpYf7lTTzMwy1S73aPJpyIBeLPKJbjOzgvEejZmZZcpBY2ZmmXLQmJlZphw0ZmaWKQeNmZllykFjZmaZctCYmVmmHDRmZpYpB42ZmWXKQWNmZply0JiZWaYcNGZmlikHjZmZZcpBY2ZmmXLQmJlZphw0ZmaWKQeNmZllykFjZmaZctCYmVmmHDRmZpYpB42ZmWWqQ6ErkLlVS6GyV6FrUXwq1xW6Bma2h/AejZmZZcpBY2ZmmXLQmJlZphw0ZmaWKQeNmZllykFjZmaZctCYmVmmHDRmZpapXQoaSTMkDcp3ZczMrPjsUs8AEXFpvitiZmbFqdmgkdQN+BlwMFAC3ARcBkyOiEWSvgF8B1gFvAlsiYgrJM0ENgGfAw4FvgaMBz4PvBQRl6TlTweGAV2AhyLin5qoyz8C56TT/gb4ZkREA9NNACYAlPTsS+nmHzfbENZK1z1e6BpQM/WsQlfBzFqgJYfOTgdWRcRRETEY+GXtG5L6AzcAxwNfIgmVXPsDpwCTgHnAbcCRwBBJ5ek010dEBVAGfFFSWRN1+WFEDEvr0QU4u6GJIuLuiKiIiIqSru7nzMyskFoSNMuAkZJulnRiROT2pngs8N8R8YeI2Ar8vN6889I9jmXA6ohYFhHbgBVAaTrNVyUtAZaShFBT535OlvSSpGUkAXZkC+pvZmYF1Oyhs4h4Q9IxwJnAv0p6MudtNTP7lvR5W85w7esOkgYCk4FhEfFReritc0MFSeoM3AFURMR7kiobm9bMzNqPZvdo0sNjf4qI+4BpwNCct18mOdy1v6QOwHmtXH5PYCOwTtKBwBlNTFsbKh9K6g6MaeWyzMysAFpy1dkQ4FZJ24CtJBcCTAOIiPclfQ94ieRigFeBFt+oJCJekbSU5FDa28ALTUz7R0n3kByGqwEWtnQ5ZmZWOGrgoq3WFSB1j4gN6R7NXODeiJibl9rlQaeDDouDxv97oathGfBVZ2bZkbQ4vVBrt+WjZ4BKSVXAcuAd4OE8lGlmZkVit2/lHBGT81GRXJLmAgPrjf5ORPwq38syM7Ns7XbQZCEizi10HczMLD/cqaaZmWWqXe7R5NOQAb1Y5JPGZmYF4z0aMzPLlIPGzMwy5aAxM7NMOWjMzCxTDhozM8uUg8bMzDLloDEzs0w5aMzMLFMOGjMzy5SDxszMMuWgMTOzTDlozMwsUw4aMzPLlIPGzMwy5aAxM7NMOWjMzCxTDhozM8uUg8bMzDLloDEzs0w5aMzMLFMOGjMzy1SHQlcgc6uWQmWvQtfCzIpZ5bpC16Bd8x6NmZllykFjZmaZctCYmVmmHDRmZpYpB42ZmWXKQWNmZply0JiZWab2mKCRVCppeaHrYWZmrbPHBI2Zme2ZMguadA/kfyTNkLRc0mxJIyW9IOlNScdKqpQ0OWee5ZJKmyi2g6RZkqolPSSpa1b1NzOz/Mi6C5rPAOcDE4CFwIXACcBo4LtAVSvLOxz4RkS8IOle4HJgWv2JJE1Il0lJz76Ubv7xrtbfdkHN1LMKXQUza0eyPnT2TkQsi4htwArgqYgIYBlQugvlvRcRL6TD95GE1k4i4u6IqIiIipKu7ufMzKyQsg6aLTnD23JebyPZm/q4Xh06N1NeNPPazMzamUJfDFADDAWQNBQY2Mz0fynp8+nwXwPPZ1c1MzPLh0IHzRzgAElVwGXAG81M/xowXlI1cAAwPdvqmZnZ7srsYoCIqAEG57y+pJH3RrWivEH5qp+ZmbWNQu/RmJlZkWt3d9iU1Bt4qoG3To2ItW1dHzMz2z3tLmjSMCkvdD3MzCw/fOjMzMwy1e72aPJtyIBeLPIv1c3MCsZ7NGZmlikHjZmZZcpBY2ZmmXLQmJlZphw0ZmaWKQeNmZllykFjZmaZctCYmVmmHDRmZpYpB42ZmWXKQWNmZply0JiZWaYcNGZmlikHjZmZZcpBY2ZmmXLQmJlZpor+xmdmlp2tW7eycuVKNm/eXOiq2C7q3LkzBx98MB07dsxsGQ4aM9tlK1eupEePHpSWliKp0NWxVooI1q5dy8qVKxk4cGBmy/GhMzPbZZs3b6Z3794OmT2UJHr37p35HqmDxsx2i0Nmz9YWn5+DxszMMlX852hWLYXKXoWuhe3JKtcVugZ7jNLrHs9reTVTz2p2mpKSEoYMGcLWrVvp0KED48eP5+qrr2affZr+P3rKlCk88cQTnHnmmdx6662trlv37t3ZsGEDNTU1/OY3v+HCCy/caZpVq1Zx1VVX8dBDDzVZ1plnnsn9998PwP3338/ll1/e6vq0Z8UfNGZW1Lp06UJVVRUAa9as4cILL2TdunXceOONTc5311138cEHH9CpU6fdWn5NTQ33339/g0HTv3//ZkMG4Iknnqgr64477ii6oPGhMzMrGv369ePuu+/mhz/8IRHBJ598wpQpUxg2bBhlZWXcddddAIwePZqNGzdy3HHH8dOf/pR58+Zx3HHHcfTRRzNy5EhWr14NQGVlJdOmTasrf/DgwdTU1OywzOuuu47nnnuO8vJybrvtth3eq6mpYfDgwQDMnDmTr3zlK5x++ukcdthhXHvttXXTlZaW8uGHH3Ldddfx1ltvUV5ezpQpU7JoooLwHo2ZFZVPfepTbNu2jTVr1vDII4/Qq1cvFi5cyJYtWxg+fDijRo3i0UcfpXv37nV7Qh999BEvvvgikpgxYwa33HIL3//+91u0vKlTpzJt2jQee+yxZqetqqpi6dKldOrUicMPP5wrr7ySQw45ZIeyli9fXlevYuGgMbOiExEAPPnkk1RXV9cdvlq3bh1vvvnmTr8ZWblyJWPHjuX3v/89f/7znzP7Tcmpp55Kr17JOeNBgwbx7rvv7hA0xcpBY2ZF5e2336akpIR+/foREdx+++2cdtppTc5z5ZVXcs011zB69GieeeYZKisrAejQoQPbtm2rm253f2+Sez6opKSEjz/+eLfK21P4HI2ZFY0PPviAiRMncsUVVyCJ0047jenTp7N161YA3njjDTZu3LjTfOvWrWPAgAEAzJo1q258aWkpS5YsAWDJkiW88847O83bo0cP1q9fn5f657Os9sR7NGaWNy25HDnfNm3aRHl5ed3lzX/zN3/DNddcA8Cll15KTU0NQ4cOJSLo27cvDz/88E5lVFZWcv755zNgwACOP/74ukA577zz+MlPfkJ5eTnDhg3js5/97E7zlpWV0aFDB4466iguueQSJk2atMvr0rt3b4YPH87gwYM544wzdumy6/ZItccyi1VF/5JYNKF7oathezL/jqZRr732GkcccUShq2G7qaHPUdLiiKjIR/k+dGZmZpnKLGgklUr6H0kzJC2XNFvSSEkvSHpT0rGSKiVNzplnuaTSJsp8WNJiSSskTciq7mZmlj9Zn6P5DHA+MAFYCFwInACMBr4LVLWyvK9HxB8kdQEWSpoTEWvrT5SG0ASAkp59Kd38411fA7M8d6tSqxDnM8wKIetDZ+9ExLKI2AasAJ6K5KTQMqB0F8q7StIrwIvAIcBhDU0UEXdHREVEVJR0dT9nZmaFlPUezZac4W05r7ely/6YHcOuc2MFSRoBjAQ+HxF/kvRMU9ObmVn7UOiLAWqAoQCShgJN/Ry3F/BRGjKfA47PvnpmZra7Cv07mjnAxZKqSM7hvNHEtL8EJkqqBl4nOXxmZu1Jvm/J0YJLy1evXs2kSZN48cUX2X///dl333259tprOffcc3d9sZWVdO/encmTJ+8wvqamhrPPPpvly5fvctmtMWLECKZNm0ZFxY5XGV966aVcc801DBo0qNF577zzTrp27crFF1/MzJkzGTVqFP3798+6yg3KLGgiogYYnPP6kkbeG9XC8rYAZ+Stgma2x4sIvvzlLzN+/Pi6+7m8++67PProoztN+/HHH9OhQ6H/t86PGTNmNDvNxIkT64ZnzpzJ4MGDCxY0hT50Zma2y55++mn23XffHb5UDz30UK688kog+YI9//zzOeeccxg1ahQbNmzg1FNPZejQoQwZMoRHHnmkbr5/+Zd/4fDDD2fkyJG8/vrrjS7z448/Zvz48ZSVlTFmzBj+9Kc/AfDP//zPDBs2jMGDBzNhwoS6jj1/8IMfMGjQIMrKyrjgggsA2LhxI1//+tcZNmwYRx99dF09Nm3axAUXXEBZWRljx45l06ZNDdZhxIgRLFq0CEhuwHb99ddz1FFHcfzxx+90i4OHHnqIRYsWcdFFF1FeXt5omVlqd0EjqbekqgYevQtdNzNrX1asWMHQoUObnGbBggXMmjWLp59+ms6dOzN37lyWLFnC/Pnz+fa3v01EsHjxYh588EGWLl3KL37xCxYuXNhoea+//joTJkygurqanj17cscddwBwxRVXsHDhQpYvX86mTZvqbhswdepUli5dSnV1NXfeeSeQhNopp5zCwoULmT9/PlOmTGHjxo1Mnz6drl27Ul1dzfXXX8/ixYubbYONGzdy/PHH88orr3DSSSdxzz337PD+mDFjqKioYPbs2VRVVdGlS5dmy8y3dhc0EbE2IsobeOz0exkzs1zf+ta3OOqooxg2bFjduC996UsccMABQHKo7bvf/S5lZWWMHDmS999/n9WrV/Pcc89x7rnn0rVrV3r27Mno0aMbXcYhhxzC8OHDARg3bhzPP/88APPnz+e4445jyJAhPP3006xYsQJI+kK76KKLuO++++oO3T355JNMnTqV8vJyRowYwebNm/nd737Hs88+y7hx4+rmKysra3ad9913X84++2wAjjnmmJ1uzNYeFMcBSzPbKx155JHMmTOn7vWPfvQjPvzwwx1Onnfr1q1uePbs2XzwwQcsXryYjh07UlpaWtf1v6Sdyn/vvfc455xzgOScx+mnn77TdJLYvHkzl19+OYsWLeKQQw6hsrKyrtzHH3+cZ599lkcffZSbbrqJFStWEBHMmTOHww8/fKdlNlSPpnTs2LFunvZ664F2t0djZtZSp5xyCps3b2b69Ol142rPmTRk3bp19OvXj44dOzJ//nzeffddAE466STmzp3Lpk2bWL9+PfPmzQOSvZeqqiqqqqrqzgP97ne/Y8GCBQA88MADnHDCCXWh0qdPHzZs2FB3o7Vt27bx3nvvcfLJJ3PLLbfwxz/+kQ0bNnDaaadx++23153HWbp0aV09Zs+eDcDy5cuprq7OSzsV+vYDRb9HM2RALxa5qw+zttHGPV1L4uGHH2bSpEnccsst9O3bl27dunHzzTc3OP1FF13EOeecQ0VFBeXl5Xzuc58DYOjQoYwdO5by8nIOPfRQTjzxxEaXecQRRzBr1iy++c1vcthhh3HZZZfRtWtX/vZv/5YhQ4ZQWlpad+juk08+Ydy4caxbt46IYNKkSey3337ccMMNXH311ZSVlRERlJaW8thjj3HZZZfxta99jbKyMsrLyzn22GPz0k6XXHIJEydOpEuXLixYsKDNz9MU/20CKiqi9uoMM8sv3yagOPg2AWZmtkdz0JiZWaYcNGa2W4r98Huxa4vPz0FjZrusc+fOrF271mGzh4oI1q5dS+fO2XaEX/RXnZlZdg4++GBWrlzJBx98UOiq2C7q3LkzBx98cKbLcNCY2S7r2LEjAwc2dXcPMx86MzOzjDlozMwsUw4aMzPLVNH3DCBpPckdOQ36AB8WuhLthNsi4XbYzm2xXR+gW0T0zUdhe8PFAK/nqxuFPZ2kRW6LhNsi4XbYzm2xXdoWpfkqz4fOzMwsUw4aMzPL1N4QNHcXugLtiNtiO7dFwu2wndtiu7y2RdFfDGBmZoW1N+zRmJlZATlozMwsU0UbNJJOl/S6pN9Kuq7Q9WkLkmokLZNUJWlROu4ASb+W9Gb6vH/O9H+fts/rkk4rXM13n6R7Ja2RtDxnXKvXXdIxaRv+VtIPJKmt12V3NdIWlZLeT7eNKkln5rxXlG0h6RBJ8yW9JmmFpL9Lx+9120UTbdE220VEFN0DKAHeAj4F7Au8AgwqdL3aYL1rgD71xt0CXJcOXwfcnA4PStulEzAwba+SQq/Dbqz7ScBQYPnurDvwMvB5QMD/A84o9LrlqS0qgckNTFu0bQEcBAxNh3sAb6Tru9dtF020RZtsF8W6R3Ms8NuIeDsi/gw8CPxVgetUKH8FzEqHZwFfzhn/YERsiYh3gN+StNseKSKeBf5Qb3Sr1l3SQUDPiFgQyV/UT3Lm2WM00haNKdq2iIjfR8SSdHg98BowgL1wu2iiLRqT17Yo1qAZALyX83olTTdqsQjgSUmLJU1Ixx0YEb+HZGMD+qXj94Y2au26D0iH648vFldIqk4PrdUeLtor2kJSKXA08BJ7+XZRry2gDbaLYg2aho4Z7g3XcQ+PiKHAGcC3JJ3UxLR7axtB4+tezG0yHfg0UA78Hvh+Or7o20JSd2AOcHVE/F9TkzYwrtjbok22i2INmpXAITmvDwZWFagubSYiVqXPa4C5JIfCVqe7u6TPa9LJ94Y2au26r0yH64/f40XE6oj4JCK2Afew/TBpUbeFpI4kX6yzI+IX6ei9crtoqC3aarso1qBZCBwmaaCkfYELgEcLXKdMSeomqUftMDAKWE6y3uPTycYDj6TDjwIXSOokaSBwGMlJvmLSqnVPD6Osl3R8eiXNxTnz7NFqv1hT55JsG1DEbZHW+z+B1yLi33Le2uu2i8baos22i0JfDZHhVRZnklxZ8RZwfaHr0wbr+ymSq0ReAVbUrjPQG3gKeDN9PiBnnuvT9nmdPewqmgbW/wGSXf+tJP91fWNX1h2oSP/Y3gJ+SNp7xp70aKQt/gtYBlSnXyIHFXtbACeQHNapBqrSx5l743bRRFu0yXbhLmjMzCxTxXrozMzM2gkHjZmZZcpBY2ZmmXLQmJlZphw0ZmaWKQeN7UTS+Wkvr/PT1w+kXVRMamU5+0m6POd1f0kP5bu+WVPSK3af3SxjoqSL81CXoyXNSIcrJU1uZLrftKCs3V6v1i5zV5ctaYSkL+S8/rKkQbtQx7Ml3dja+Wz3OGisId8ALo+IkyX9BfCFiCiLiNtaWc5+QF3QRMSqiBiTx3ruMSLizoj4SR6K+i5wewuW94Xmptkdkjq08TJHALnlf5mkh+EWS+v8ODBaUte81cya5aDZi0kaJ+nl9D4Ud0kqkfSPJD/uulPSrcCTQL90mhMlfVrSL9OOO5+T9Lm0rAMlzZX0Svr4AjAV+HQ6762SSpXeI0XSS5KOzKnLM0ruc9Et7dxvoaSlknbqdVvSQZKeTctdLunEdPx0SYuU3G/jxpzpayR9T9KC9P2hkn4l6S1JE9NpRqRlzpX0qqQ7Je3099FQmzUwzdS0jGpJ09JxlZImp3t1VTmPTyQdKqmvpDnpei+UNLyBcnsAZRHxSs7oQWnbvS3pqpxpN6TP+0i6I22TxyQ9ISk37K+UtETJ/UVqP8sGPwNJl0j6uaR56XZRv361y2zw82nAlLQtX5b0mXTendpBSSeQE4FJaZlfBEYDt6avP93EdjlT0r8p2Tu/OZIfDj4DnN1InSwLhf7Fqh+FeQBHAPOAjunrO4CL0+FngIp0uJQd72vyFHBYOnwc8HQ6/FOSjvoguR9QrwbmrXsNTAJuTIcPAt5Ih78HjEuH9yPp3aFbvbp/m+09H5QAPdLhA3LGPUPypQzJfXouS4dvI/kVdA+gL7AmHT8C2EzSw0IJ8GtgTM78fZpqs5y6HUDyS+raH0Pvlz5XUu++H8C3gJ+lw/cDJ6TDf0nSVUj9z+xkYE7O60rgNyT3DOkDrM2p24b0eQzwBMk/lX8BfFRvva5Mhy8HZjT1GQCXkPQ0cED9utVbZoOfT71pa3KmuRh4rKl2qN9+wMza9Whmu5wJPEbOvZaAi4DbC/03uDc9dtr9tb3GqcAxwEIlN8jrwvbOBRukpOfXLwA/1/ab6nVKn08h+cIgIj4B1innzoUN+BnJl/k/AV8Ffp6OH0VyaKP23ENn0i+cnHkXAvcq6STw4YioSsd/VcntETqQhNcgklCB7X3dLQO6R3JPjvWSNkvaL33v5Yh4O13XB0j27HLPKbWkzf6PJLBmSHqc5EtuJ+key6VA7X/7I0n2Tmon6SmpR1rPWgcBH9Qr6vGI2AJskbQGOJAdu3E/Afh5JJ0m/m/6n32u2o4mFwNfSYcb+wwAfh0Rzd3rprHPp74Hcp5rD8s22A5NLayZ7RKS9f8k5/UaoH8z62B55KDZewmYFRF/34p59gH+GBHlu7vwiHhf0lpJZcBY4Js59TovIl5vYt5nldwC4Szgv5Qc4nsOmAwMi4iPJM0k+YKstSV93pYzXPu69u+gfn9M9V8322YR8bGkY0lC6QLgCpIQ3l5I0pHhfwKjI2JDOnof4PMRsamxsoFN9daJeuvyCTv/TTd3m93a+XPnbfAzkHQcsLGZ8hr8fKLh81PRwHCD7aCm7xbc3HZZv86dSdrS2ojP0ey9ngLGSOoHdfdRP7SpGSK5f8U7ks5P55Gko3LKuywdXyKpJ7Ce5BBVYx4ErgV6RcSydNyvSM4bKC3r6PozpfVcExH3kHxhDwV6knyhrJN0IMk9eVrrWCU9fu9DEn7P13u/2TZL/7vuFRFPAFeT3Ocj9/2OJHtz34mIN3LeepIklGqn22G+1GvAZ1q5Ts8D56Xnag4kOUTYnGY/g6Y08vk0ZGzO84J0uLF2qL8t1b1uZrtsyGfZ3kuxtQEHzV4qIl4F/oHkjpzVJIexDmp6LiA5vv0NSbW9RNeerP874GRJy0gOwxwZEWuBF9ITwrc2UNZDJP/1/yxn3E1AR6BayYUDNzUw3wigStJS4DzgPyI5Qb40rdO9wAstWJf6FpBcwLAceIfknj51WthmPYDH0vf/m+RcVK4vAMOAG7X9goD+wFVAhZILCF4lOfm9g4j4H6BXc4eS6plDcihtOXAXyV0V1zUzT0s+g6aMoN7n08h0nSS9RLLt1LZTY+0wDzg3ba8TSf5JmaLkYoVP0/h22ZCTSa4+szbi3pvNSK46IznZ3K6vRlLyW6b1ETGjFfN0j4gNknqT3HNoeET8b2aVbMfSvbr7I+LUQtdlb+JzNGZ7lunA+a2c57H0god9gZv21pBJ/SXJVXHWhrxHY2ZmmfI5GjMzy5SDxszMMuWgMTOzTDlozMwsUw4aMzPL1P8HK8Ep7FBEVUkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import arviz as az\n",
    "\n",
    "pd.DataFrame({\"Default init\": az.summary(idata_pymc4, var_names=[\"~a\", \"~b\"])[\"ess_bulk\"],\n",
    "              \"Grad-based init\": az.summary(idata_pymc4_grad, var_names=[\"~a\", \"~b\"])[\"ess_bulk\"]}).plot.barh()\n",
    "plt.xlabel(\"effective sample size (higher is better)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464dbf3",
   "metadata": {},
   "source": [
    "## A Look Towards the Future\n",
    "\n",
    "As mentioned in the beginning, `aesara` is a unique library in the PyData ecosystem as it is the only one that provides a static, mutable computation graph. Having direct access to this computation graph allows for many interesting features. Above we already mentioned simplfications like turning `exp(log(x))` into `x`, and `aesara` already implements many of these. While we don't have proper benchmarks, we noticed major speed-ups of porting models from PyMC3 to 4.0, even without the JAX backend.\n",
    "\n",
    "But these graph rewrites can become much more sophisticated. For example, [a beta prior on a binomial likelihood can be replaced with its analytical solution directly by exploiting conjugacy](https://github.com/aesara-devs/aemcmc/pull/29). \n",
    "\n",
    "Or a hierarchical model written in a centered parameterization can automatically be converted to its [non-centered analog](https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/) which often samples much more efficiently. These model reparameterizations can make a huge difference in how well a model samples. Unforutnately, these reparameterizations still require intimate knowledge of the math and a deep understanding of the posterior geometry, nothing a casual PyMC user would be familiar with. So with these graph rewrites we will be able to automatically reparameterize a PyMC model for you and find the configuration that samples most efficiently.\n",
    "\n",
    "**In sum, we believe PyMC 4.0 is the best version yet and pushes the state of the art in probabilistic programming. But it's also stepping stone to many more innovations to come. Thanks for being a part of it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4454d",
   "metadata": {},
   "source": [
    "## Accolades\n",
    "\n",
    "While many people contributed to this effort, we would like to highlight the outstanding contributions of [Brandon Willard](https://brandonwillard.github.io), [Ricardo Vieira](https://github.com/ricardoV94), and [Kaustubh Chaudhari](https://github.com/kc611) who lead this gigantic effort."
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/badf23b78fd1237d16f4c1909ddbe3e3"
  },
  "gist": {
   "data": {
    "description": "PyMC3 vs PyMC 4.0.ipynb",
    "public": true
   },
   "id": "badf23b78fd1237d16f4c1909ddbe3e3"
  },
  "kernelspec": {
   "display_name": "pymc4b5",
   "language": "python",
   "name": "pymc4b5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
